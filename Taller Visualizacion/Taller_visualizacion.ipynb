{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMQejRm/GIHeq4rh0ADXkS0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ======================================================\n","# ETL PIPELINE: Superstore ‚Üí Google Sheets (modelo Star)\n","# Visualizaci√≥n: Looker Studio\n","# ======================================================"],"metadata":{"id":"gmaIrdEvr9TC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Importamos librer√≠as necesarias"],"metadata":{"id":"QXquTkJTtnO_"}},{"cell_type":"code","source":["# --- 1. Librer√≠as necesarias ---\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","from google.colab import auth\n","import gspread\n","from google.auth import default\n","from googleapiclient.discovery import build"],"metadata":{"id":"-bbY6UORr-nY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Autenticaci√≥n con Google"],"metadata":{"id":"jBJ5A2ORtsDn"}},{"cell_type":"markdown","source":["Usamos la librer√≠a google.auth para tener acceso a crear Documento de Google Sheets. Cada tab/hoja de c√°lculo, equivale a una tabla de una Base de Datos"],"metadata":{"id":"z6ryvE4-5j1w"}},{"cell_type":"code","source":["# --- 2. Autenticaci√≥n con Google ---\n","auth.authenticate_user()\n","creds, _ = default()\n","gc = gspread.authorize(creds)\n","print(\"‚úÖ Autenticado con Google correctamente.\")"],"metadata":{"id":"YBCfXzGesBrA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Importar / Cargar Dataset en formato csv"],"metadata":{"id":"xjRvVNH_twan"}},{"cell_type":"markdown","source":["Vamos a user el dataset Superstore\n","<BR>\n","Ver en [Kaggle](https://www.kaggle.com/datasets/vivek468/superstore-dataset-final)"],"metadata":{"id":"WEPMnFgIub9P"}},{"cell_type":"markdown","source":["Como venimos haciendo hasta ahora, descargamos el Dataset \"Superstore\" y lo guardamos en nuestro Google Drive. Luego lo cargamos en memoria para el procesamiento."],"metadata":{"id":"7P1UKTO3562Q"}},{"cell_type":"code","source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"vivek468/superstore-dataset-final\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"id":"rCA8s5nNsR9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /root/.cache/kagglehub/datasets/vivek468/superstore-dataset-final/versions/1"],"metadata":{"id":"V7qGOMh4tV6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Montar la unidad\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"eo9dXRF8tZ1v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# En caso que necesiten hace un unmount de la unidad\n","# drive.flush_and_unmount"],"metadata":{"id":"rcvHw7XTz0Ls"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ahora copiar el dataset descargado a nuestro Google Drive\n","import os, shutil\n","# Carpeta destino\n","dest_dir = \"/content/drive/MyDrive/datasets/\"\n","\n","# Copiar todos los archivos del dataset al destino\n","for file in os.listdir(path):\n","    shutil.copy(os.path.join(path, file), dest_dir)\n","\n","# print(\"Archivos copiados a:\", dest_dir)\n","# print(\"Contenido:\", os.listdir(dest_dir))\n","\n","os.listdir(dest_dir)"],"metadata":{"id":"w8KxKXLQteXw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Usar el m√©todo read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n","os.chdir('/content/drive/MyDrive/datasets')\n","df = pd.read_csv(\"Sample - Superstore.csv\", encoding=\"latin1\")"],"metadata":{"id":"_1MLsCwptjE3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.sample()"],"metadata":{"id":"czHIGtDLdKXj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Limpieza de datos"],"metadata":{"id":"vuxVJxjct8bn"}},{"cell_type":"markdown","source":["Asi como trabajamos en nuestra Pre-entrega, realizamos una limpieza de duplicados y nulos para alimentar con datos de calidad la pr√≥xima etapa."],"metadata":{"id":"IyfFtNUd6M4g"}},{"cell_type":"code","source":["# Normalizar nombres de columnas\n","df.columns = df.columns.str.strip().str.replace(\" \", \"_\").str.lower()"],"metadata":{"id":"0Ula3hxLvhu2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"WaUuzNQCcJ5U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 4. Limpieza b√°sica ---\n","df = df.dropna(subset=[\"order_date\", \"sales\", \"profit\"])\n","df[\"order_date\"] = pd.to_datetime(df[\"order_date\"])\n","df[\"ship_date\"] = pd.to_datetime(df[\"ship_date\"])"],"metadata":{"id":"nMaQYY1KvR1f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Crear campos derivados\n","df[\"profit_margin\"] = df[\"profit\"] / df[\"sales\"]\n","df[\"order_year\"] = df[\"order_date\"].dt.year\n","df[\"order_month\"] = df[\"order_date\"].dt.month\n","df[\"order_quarter\"] = df[\"order_date\"].dt.quarter\n","df[\"order_day\"] = df[\"order_date\"].dt.day\n","df[\"order_week\"] = df[\"order_date\"].dt.isocalendar().week.astype(int)\n","\n","print(\"üßπ Limpieza y enriquecimiento de datos completado.\")"],"metadata":{"id":"nv4eb0SouB6f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Construcci√≥n de las dimensiones (modelo estrella)"],"metadata":{"id":"q649g9uZvq02"}},{"cell_type":"markdown","source":["Este es un concepto nuevo. Para poder representar los datos en Looker Studio (u otra herramienta de visualizaci√≥n), necesitamos que nuestros datos se encuentren organizados en una Base de Datos Operacional (OLAP). Esta base consta de una tabla de \"facts\" o \"hechos\" con m√©tricas que luego se puede agregar (sumar, promediar, obtener m√°ximos, etc) y tantan tablas de dimensiones como necesitemos. Estas tablas de dimensiones nos permiten analizar los datos desde m√∫ltiples perspectivas (como si fuera un cubo, donde cada lado se corresponde con una dimensi√≥n). Las dimensiones m√°s comunes son: la tempora y la geogr√°fica, en nuestro caso sumamos adem√°s la de categor√≠as y de clientes."],"metadata":{"id":"h0tGPyBF6Zlg"}},{"cell_type":"markdown","source":["A continuaci√≥n cremos primeros las tablas correspondientes a cada dimensi√≥n. En nuestro caso usaremos tablas \"desnomarmalizadas\", y cada una tendra una clave primaria, que ser√° referenciada desde la tabla de hechos, o fact table, que veremos debajo."],"metadata":{"id":"fCVxCueH7nUI"}},{"cell_type":"code","source":["# Dimensi√≥n Fecha\n","dim_date = df[[\"order_date\", \"order_year\", \"order_quarter\", \"order_month\", \"order_week\", \"order_day\"]] \\\n","    .drop_duplicates().reset_index(drop=True)\n","dim_date.insert(0, \"date_id\", range(1, len(dim_date)+1))"],"metadata":{"id":"z--wQ8Ncv3qm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dimensi√≥n Producto\n","dim_product = df[[\"category\", \"sub-category\", \"product_name\"]] \\\n","    .drop_duplicates().reset_index(drop=True)\n","dim_product.insert(0, \"product_id\", range(1, len(dim_product)+1))"],"metadata":{"id":"4gXcTNBJv7Yt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dimensi√≥n Geograf√≠a\n","dim_geo = df[[\"country\", \"region\", \"state\", \"city\"]] \\\n","    .drop_duplicates().reset_index(drop=True)\n","dim_geo.insert(0, \"geo_id\", range(1, len(dim_geo)+1))"],"metadata":{"id":"Hz2Mng9KwEmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dimensi√≥n Cliente\n","dim_customer = df[[\"customer_id\", \"customer_name\", \"segment\"]] \\\n","    .drop_duplicates().reset_index(drop=True)\n","dim_customer.insert(0, \"customer_sk\", range(1, len(dim_customer)+1))\n","\n","print(\"üìö Dimensiones creadas:\")\n","print(f\"  dim_date={len(dim_date)}, dim_product={len(dim_product)}, dim_geo={len(dim_geo)}, dim_customer={len(dim_customer)}\")"],"metadata":{"id":"l96kjKEKwHwW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. Construcci√≥n de la Tabla de Hechos (o bien conocida como Fact Table)"],"metadata":{"id":"qFTdtVVy5yuQ"}},{"cell_type":"markdown","source":["Esta es la tabla que mencionamos arteriormente, que solo contiene las m√©tricas y las Claves Primarias a las tablas de dimensiones."],"metadata":{"id":"Lfqca7JY7Rxh"}},{"cell_type":"code","source":["# Mapear claves surrogate\n","date_map = dict(zip(dim_date[\"order_date\"], dim_date[\"date_id\"]))\n","prod_map = dict(zip(dim_product[\"product_name\"], dim_product[\"product_id\"]))\n","geo_map = dict(zip(dim_geo[\"city\"], dim_geo[\"geo_id\"]))\n","cust_map = dict(zip(dim_customer[\"customer_id\"], dim_customer[\"customer_sk\"]))\n","\n","fact_sales = pd.DataFrame({\n","    \"order_id\": df[\"order_id\"],\n","    \"date_id\": df[\"order_date\"].map(date_map),\n","    \"product_id\": df[\"product_name\"].map(prod_map),\n","    \"geo_id\": df[\"city\"].map(geo_map),\n","    \"customer_id\": df[\"customer_id\"].map(cust_map),\n","    \"sales\": df[\"sales\"],\n","    \"profit\": df[\"profit\"],\n","    \"quantity\": df[\"quantity\"],\n","    \"discount\": df[\"discount\"],\n","    \"profit_margin\": df[\"profit_margin\"]\n","})\n","\n","print(f\"üßæ Tabla de hechos creada: {len(fact_sales)} registros.\")"],"metadata":{"id":"AJhghN5C2i1b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. Poblar las tablas de un Documento de Google Sheets"],"metadata":{"id":"YXx8SP1L7mqP"}},{"cell_type":"markdown","source":["Procedemos ahora a \"poblar\" nuestras tablas. En este caso usamos hojas de c√°lculo de Google Sheets, que luego podemos reemplazar por una Base de Datos Relacional, como ser PostgreSQL."],"metadata":{"id":"4VL0D-Xn7_Vp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJaPeBZ7r1jo"},"outputs":[],"source":["# Buscamos el archivo \"DW_Superstore_OLAP_Star\"\n","# Si existe lo reutilizamos, sino lo creamos.\n","# La idea es que el ETL sea reproducible\n","\n","# ----------------------------------------------------------\n","# Buscar o crear el archivo en Google Drive\n","service = build('drive', 'v3', credentials=creds)\n","\n","file_name = \"DW_Superstore_OLAP\"\n","results = service.files().list(\n","    q=f\"name='{file_name}' and mimeType='application/vnd.google-apps.spreadsheet'\",\n","    spaces='drive'\n",").execute()\n","\n","if results['files']:\n","    spreadsheet_id = results['files'][0]['id']\n","    spreadsheet = gc.open_by_key(spreadsheet_id)\n","    print(\"üìÇ Archivo existente encontrado:\", spreadsheet.url)\n","else:\n","    spreadsheet = gc.create(file_name)\n","    print(\"üÜï Archivo nuevo creado:\", spreadsheet.url)\n","\n","# ----------------------------------------------------------\n","# Mantener \"Hoja 1\" intacta y limpiar las dem√°s hojas antes de reescribirlas\n","worksheets = spreadsheet.worksheets()\n","existing_titles = [ws.title for ws in worksheets]\n","\n","print(\"üìÑ Hojas existentes:\", existing_titles)\n","\n","# ----------------------------------------------------------\n","# Definir las tablas OLAP a subir\n","tables = {\n","    \"dim_date\": dim_date,\n","    \"dim_product\": dim_product,\n","    \"dim_geo\": dim_geo,\n","    \"dim_customer\": dim_customer,\n","    \"fact_sales\": fact_sales\n","}\n","\n","# ----------------------------------------------------------\n","# Subir las tablas sin eliminar hojas (solo limpiar contenido)\n","for name, df_table in tables.items():\n","    # Convertir columnas datetime a string\n","    for col in df_table.columns:\n","        if np.issubdtype(df_table[col].dtype, np.datetime64):\n","            df_table[col] = df_table[col].dt.strftime('%Y-%m-%d')\n","\n","    # Si la hoja ya existe, limpiar su contenido; si no, crearla\n","    existing_titles = [ws.title for ws in spreadsheet.worksheets()]\n","    if name in existing_titles:\n","        ws = spreadsheet.worksheet(name)\n","        ws.clear()\n","        print(f\"üßπ Hoja existente '{name}' limpiada.\")\n","    else:\n","        ws = spreadsheet.add_worksheet(\n","            title=name,\n","            rows=str(len(df_table) + 1),\n","            cols=str(len(df_table.columns) + 1)\n","        )\n","        print(f\"üÜï Hoja '{name}' creada.\")\n","\n","    # Subir los datos (encabezados + valores)\n","    ws.update([df_table.columns.values.tolist()] + df_table.astype(str).values.tolist())\n","    print(f\"üìà Hoja '{name}' actualizada correctamente ({len(df_table)} filas).\")\n","\n","print(\"‚úÖ Data Warehouse OLAP actualizado correctamente.\")\n","print(\"üìä URL:\", spreadsheet.url)\n","\n"]},{"cell_type":"markdown","source":["Comprobar que las hojas del Google Sheet se completaron y continuar el armado del Dashboard desde Looker Studio.\n","<BR>\n","Como primer paso, se importan las tablas. Luego, a partir de los KPIs (primary key indicators) se arman los join y luego se agregan los gr√°ficos y se configuran en el panel de propiedades."],"metadata":{"id":"eKp1bL728dAI"}},{"cell_type":"markdown","source":["# Validaciones"],"metadata":{"id":"oB7OFz82ZpHu"}},{"cell_type":"markdown","source":["Aqu√≠ podemos hacer join/merge y agregaciones para validar los datos que arroja Looker Studio."],"metadata":{"id":"jI_QAGRA8Vph"}},{"cell_type":"code","source":["fact_sales[\"customer_id\"]=fact_sales[\"customer_id\"].astype(str)\n","dim_customer[\"customer_sk\"]=dim_customer[\"customer_sk\"].astype(str)\n","facts_customer = pd.merge(fact_sales, dim_customer, left_on=\"customer_id\", right_on=\"customer_sk\", how=\"left\")"],"metadata":{"id":"HIB803vWZmfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["facts_customer.head()"],"metadata":{"id":"h7fK3p2BqPw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["facts_customer.columns"],"metadata":{"id":"Nf9CS7gbpVmk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["facts_customer.groupby(\"customer_name\").agg(\n","    {\"sales\":\"sum\",\n","     \"profit\": \"sum\"}\n",")"],"metadata":{"id":"npzY7rwdpEEM"},"execution_count":null,"outputs":[]}]}